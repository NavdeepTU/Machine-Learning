{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Get the path to the parent directory\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "# Specify the filename\n",
    "filename = 'final.sqlite'\n",
    "\n",
    "# Construct the path to the file in the parent directory\n",
    "file_path = os.path.join(parent_dir, filename)\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.isfile(file_path):\n",
    "    conn = sqlite3.connect(file_path)\n",
    "    final = pd.read_sql_query('select * from reviews', conn)\n",
    "    conn.close()\n",
    "else:\n",
    "    print('Please run Text Preprocessing code file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>CleanedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>bought sever vital can dog food product found ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>product arriv label jumbo salt peanut peanut a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>confect around centuri light pillowi citrus ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>look secret ingredi robitussin believ found go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>great taffi great price wide assort yummi taff...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Id   ProductId          UserId                      ProfileName  \\\n",
       "0      0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1      1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2      2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3      3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4      4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      1  1303862400   \n",
       "1                     0                       0      0  1346976000   \n",
       "2                     1                       1      1  1219017600   \n",
       "3                     3                       3      0  1307923200   \n",
       "4                     0                       0      1  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \\\n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...   \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...   \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...   \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...   \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...   \n",
       "\n",
       "                                         CleanedText  \n",
       "0  bought sever vital can dog food product found ...  \n",
       "1  product arriv label jumbo salt peanut peanut a...  \n",
       "2  confect around centuri light pillowi citrus ge...  \n",
       "3  look secret ingredi robitussin believ found go...  \n",
       "4  great taffi great price wide assort yummi taff...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting data based on time for time based splitting\n",
    "final = final.sort_values('Time', axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')\n",
    "# Now we will perform time based slicing\n",
    "x_train_raw = final['CleanedText'][0:50000]\n",
    "y_train = final['Score'][0:50000]\n",
    "x_cv_raw = final['CleanedText'][50000:70000]\n",
    "y_cv = final['Score'][50000:70000]\n",
    "x_test_raw = final['CleanedText'][70000:87773]\n",
    "y_test = final['Score'][70000:87773]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some common initializations used in whole of the assignment\n",
    "neighbors = np.arange(1,30,1)\n",
    "mask = neighbors%2 != 0\n",
    "neighbors = neighbors[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will be training BOW, Tfidf and W2V features using both brute force and kd-tree implementaion of KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying KNN-brute force using BOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "count_vect.fit(x_train_raw.values)\n",
    "filename = 'brute_bow'\n",
    "pickle.dump(count_vect, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = pickle.load(open('brute_bow', 'rb'))\n",
    "x_train = count_vect.transform(x_train_raw.values)\n",
    "x_cv = count_vect.transform(x_cv_raw.values)\n",
    "train_auc = []\n",
    "cv_auc = []\n",
    "# performing simple cross-validation\n",
    "for k in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(x_train, y_train)\n",
    "    y_train_pred = []\n",
    "    y_cv_pred = []\n",
    "    for i in range(0, x_train.shape[0], 1000): # using loop to avoid memory error\n",
    "        y_train_pred.extend(knn.predict_proba(x_train[i:i+1000,:])[:,1])\n",
    "    for i in range(0, x_cv.shape[0], 1000):\n",
    "        y_cv_pred.extend(knn.predict_proba(x_cv[i:i+1000,:])[:,1])\n",
    "    train_auc.append(roc_auc_score(y_train, y_train_pred))\n",
    "    cv_auc.append(roc_auc_score(y_cv, y_cv_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(neighbors, train_auc, label='Train AUC', marker='o')\n",
    "# plt.scatter(neighbors, train_auc, label='Train AUC')\n",
    "plt.plot(neighbors, cv_auc, label='CV AUC', marker='o')\n",
    "plt.legend()\n",
    "plt.xlabel(\"K: hyperparameter\")\n",
    "plt.ylabel('AUC')\n",
    "plt.title('ERROR PLOTS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63317    bought apart infest fruit fli hour trap mani f...\n",
       "1144     realli good idea final product outstand use de...\n",
       "1143     receiv shipment could hard wait tri product lo...\n",
       "26904    noth product bother link top page buy use chew...\n",
       "26905    love stuff doesnt rot gum tast good go buy gum...\n",
       "55686    youv never tri kona coffe aloha island definit...\n",
       "36161    fresh lime underappreci joy kitchen squirt lim...\n",
       "36308    groceri store kind coffe laid one tri tast lik...\n",
       "36307    blend one starbuck gentler blend like tast sta...\n",
       "10496    chatchi favorit afternoon treat becam mysteri ...\n",
       "26903    tenni player hubbi mine got pack rack opel cor...\n",
       "85432    forget store bought jerki make premium jerki a...\n",
       "84321    sauc excel inde spici brand also make mild ver...\n",
       "56470    youv never real swiss fondu your realli miss s...\n",
       "77727    definit cute product order get nice amount can...\n",
       "37088    discov oil year ago bought one flavor thunders...\n",
       "45051    huge fan jelli belli jelli bean realli enjoy g...\n",
       "23046    yes juic appar person love drink lead orang ca...\n",
       "77127    panko bread crumb awesom use bread make light ...\n",
       "82754    ive tri mani packag chai product liquid dri so...\n",
       "72750    high recommend busi compani like job nice pric...\n",
       "77128    japanes version breadcrumb portugues panko use...\n",
       "82776    first turn onto chocol visit privat mexican th...\n",
       "82753    search great decaf chai final found excel made...\n",
       "23196    enjoy rich spread toast crumpet english muffin...\n",
       "83219    good get half pound cotswold english pub chees...\n",
       "7402     winter fresh blueberri exceed food budget dri ...\n",
       "23955    love sleepytim tea ive drink year sooth bed ta...\n",
       "85656    theyr shape like lego tast like sweettart need...\n",
       "83110    exagerr roar blue wonder mixtur strength subtl...\n",
       "                               ...                        \n",
       "328      ahead drink brand serv neighborhood cafe must ...\n",
       "20741    normal buy hous autri similar special bread fr...\n",
       "37186    first time nyc sheraton attend open tenni dont...\n",
       "52802    everyth ever tast caribou step competit bag co...\n",
       "29932    doesnt tast like bergamot thusli doesnt tast l...\n",
       "14417    favorit coffe keurig coffeemak conveni get ama...\n",
       "20740    mother use make pork shake bake quit lot love ...\n",
       "73153    bigelow loyal year especi super fruit kind tea...\n",
       "85718    enjoy cinnamon excel coffe smooth lean toward ...\n",
       "3955     aw sight pan made sick smell like potato duh p...\n",
       "87309    coffe tast great great like coffe stronger sid...\n",
       "62668    inform funni amazon review product sold singl ...\n",
       "3970     bought bisquick first thing tri make drop bisc...\n",
       "2009     love peanut satay product truli terribl way re...\n",
       "66779    doesnt like mani dairi product love gelatin ve...\n",
       "51041    stuff wonder even talk pharmaci thought full v...\n",
       "20298    got singl pot sampl coffe enjoy much get heart...\n",
       "4989     googl propylen glycol find bought product alon...\n",
       "57008    receiv canist mold cover jerki contact lowrey ...\n",
       "46441    disc tassimo coffe machin incred easi use amaz...\n",
       "75522    favorit green tea right strength brew biggest ...\n",
       "59108    easi use automat espresso machin use salon wor...\n",
       "64213    excit find cherri husband love disappoint old ...\n",
       "18165    happi product surpris versatil use ton differ ...\n",
       "29015    pirat booti month old daughter favorit snack s...\n",
       "72564    thank much sourc lindt peanut butter truffl ye...\n",
       "7142     got mail nice packag open see singl serv bag h...\n",
       "61219    love product four year old gfcf diet perfect p...\n",
       "9345     recent bought keurig coffe maker husband love ...\n",
       "77064    dog buster love nummi tum tum pure can pumpkin...\n",
       "Name: CleanedText, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_k = \n",
    "brute_bow_k = optimal_k\n",
    "knn_for_optimal_k = KNeighborsClassifier(n_neighbors=optimal_k)\n",
    "knn_for_optimal_k.fit(x_train, y_train)\n",
    "filename = 'brute_bow_knn'\n",
    "pickle.dump(knn_for_optimal_k, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
